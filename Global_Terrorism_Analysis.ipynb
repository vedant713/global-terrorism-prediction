{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\ravin\\\\Downloads\\\\Folders\\\\Global Terrorism - START data\\\\gt.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m      7\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mravin\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mFolders\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mGlobal Terrorism - START data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mgt.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the dataframe\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ravin\\\\Downloads\\\\Folders\\\\Global Terrorism - START data\\\\gt.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:\\\\Users\\\\ravin\\\\Downloads\\\\Folders\\\\Global Terrorism - START data\\\\gt.csv'\n",
    "df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Display summary statistics of the dataframe\n",
    "print(df.describe())\n",
    "\n",
    "# Display information about the dataframe\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Fill or drop missing values as appropriate\n",
    "df['city'].fillna('Unknown', inplace=True)\n",
    "df['provstate'].fillna('Unknown', inplace=True)\n",
    "df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count incidents by country\n",
    "country_counts = df['country_txt'].value_counts().head(10)\n",
    "print(country_counts)\n",
    "\n",
    "# Visualize incidents by country\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y=country_counts.index, x=country_counts.values, palette='viridis')\n",
    "plt.title('Top 10 Countries by Number of Terrorist Attacks')\n",
    "plt.xlabel('Number of Attacks')\n",
    "plt.ylabel('Country')\n",
    "plt.show()\n",
    "\n",
    "# Count incidents by region\n",
    "region_counts = df['region_txt'].value_counts()\n",
    "print(region_counts)\n",
    "\n",
    "# Visualize incidents by region\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y=region_counts.index, x=region_counts.values, palette='plasma')\n",
    "plt.title('Terrorist Attacks by Region')\n",
    "plt.xlabel('Number of Attacks')\n",
    "plt.ylabel('Region')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend of attacks over the years\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df.groupby('iyear').size())\n",
    "plt.title('Trend of Terrorist Attacks Over the Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()\n",
    "\n",
    "# Most common attack types\n",
    "attack_type_counts = df['attacktype1_txt'].value_counts()\n",
    "print(attack_type_counts)\n",
    "\n",
    "# Visualize common attack types\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y=attack_type_counts.index, x=attack_type_counts.values, palette='coolwarm')\n",
    "plt.title('Most Common Attack Types')\n",
    "plt.xlabel('Number of Attacks')\n",
    "plt.ylabel('Attack Type')\n",
    "plt.show()\n",
    "\n",
    "# Analysis of the most targeted types of victims\n",
    "target_type_counts = df['targtype1_txt'].value_counts()\n",
    "print(target_type_counts)\n",
    "\n",
    "# Visualize target types\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y=target_type_counts.index, x=target_type_counts.values, palette='magma')\n",
    "plt.title('Most Targeted Victim Types')\n",
    "plt.xlabel('Number of Attacks')\n",
    "plt.ylabel('Victim Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly trend of terrorist activities\n",
    "plt.figure(figsize=(12, 6))\n",
    "df.groupby('iyear').size().plot(kind='bar', color='skyblue')\n",
    "plt.title('Yearly Trend of Terrorist Attacks')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()\n",
    "\n",
    "# Monthly distribution of terrorist activities\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['imonth'].value_counts().sort_index().plot(kind='bar', color='lightgreen')\n",
    "plt.title('Monthly Distribution of Terrorist Attacks')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()\n",
    "\n",
    "# Day-wise distribution of terrorist activities\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['iday'].value_counts().sort_index().plot(kind='bar', color='lightcoral')\n",
    "plt.title('Day-wise Distribution of Terrorist Attacks')\n",
    "plt.xlabel('Day of the Month')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack types\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['attacktype1_txt'].value_counts().plot(kind='bar', color='purple')\n",
    "plt.title('Types of Terrorist Attacks')\n",
    "plt.xlabel('Attack Type')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()\n",
    "\n",
    "# Weapon types\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['weaptype1_txt'].value_counts().plot(kind='bar', color='orange')\n",
    "plt.title('Types of Weapons Used in Terrorist Attacks')\n",
    "plt.xlabel('Weapon Type')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of fatalities\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['nkill'], bins=50, kde=True, color='blue')\n",
    "plt.title('Distribution of Fatalities in Terrorist Attacks')\n",
    "plt.xlabel('Number of Fatalities')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "# Distribution of wounded\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['nwound'], bins=50, kde=True, color='red')\n",
    "plt.title('Distribution of Wounded in Terrorist Attacks')\n",
    "plt.xlabel('Number of Wounded')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of fatalities vs. wounded\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x='nkill', y='nwound', data=df, alpha=0.5)\n",
    "plt.title('Fatalities vs. Wounded in Terrorist Attacks')\n",
    "plt.xlabel('Number of Fatalities')\n",
    "plt.ylabel('Number of Wounded')\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top perpetrator groups\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['gname'].value_counts().head(10).plot(kind='bar', color='darkgreen')\n",
    "plt.title('Top Perpetrator Groups')\n",
    "plt.xlabel('Perpetrator Group')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()\n",
    "\n",
    "# Uncertainty in perpetrator information\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='guncertain1', data=df, palette='Set1')\n",
    "plt.title('Uncertainty in Perpetrator Information')\n",
    "plt.xlabel('Uncertainty (1 = Uncertain, 0 = Certain)')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target types\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['targtype1_txt'].value_counts().plot(kind='bar', color='darkorange')\n",
    "plt.title('Types of Targets in Terrorist Attacks')\n",
    "plt.xlabel('Target Type')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()\n",
    "\n",
    "# Victims by nationality\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['natlty1_txt'].value_counts().head(10).plot(kind='bar', color='cyan')\n",
    "plt.title('Top Nationalities of Victims')\n",
    "plt.xlabel('Nationality')\n",
    "plt.ylabel('Number of Victims')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incidents in specific countries (e.g., Iraq, Pakistan)\n",
    "for country in ['Iraq', 'Pakistan']:\n",
    "    country_df = df[df['country_txt'] == country]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(x='iyear', data=country_df, palette='coolwarm')\n",
    "    plt.title(f'Terrorist Attacks in {country} Over the Years')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Attacks')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "# Geographic clustering of incidents within a country (e.g., India)\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Filter data for a specific country (e.g., India)\n",
    "india_df = df[df['country_txt'] == 'India']\n",
    "\n",
    "# Create a map centered around India\n",
    "m = folium.Map(location=[20.5937, 78.9629], zoom_start=5)\n",
    "\n",
    "# Add incidents to the map\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "for idx, row in india_df.iterrows():\n",
    "    folium.Marker([row['latitude'], row['longitude']], popup=row['city']).add_to(marker_cluster)\n",
    "\n",
    "# Display the map\n",
    "m.save('india_terrorism_map.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, classification_report, accuracy_score\n",
    "import xgboost as xgb\n",
    "# Fill missing categorical values\n",
    "df['city'].fillna('Unknown', inplace=True)\n",
    "df['provstate'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Fill remaining missing values with 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Verify missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for categorical variables\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "df['attacktype1_txt'] = encoder.fit_transform(df['attacktype1_txt'])  # Encode Attack Type\n",
    "df['targtype1_txt'] = encoder.fit_transform(df['targtype1_txt'])  # Encode Target Type\n",
    "df['weaptype1_txt'] = encoder.fit_transform(df['weaptype1_txt'])  # Encode Weapon Type\n",
    "\n",
    "# Define feature columns for Regression (Fatalities) - Attack Type is a valid feature here\n",
    "features_reg = ['iyear', 'imonth', 'iday', 'country', 'region', 'attacktype1_txt', 'targtype1_txt', 'weaptype1_txt']\n",
    "\n",
    "# Define feature columns for Classification (Attack Type) - Attack Type MUST be removed to avoid leakage\n",
    "features_clf = ['iyear', 'imonth', 'iday', 'country', 'region', 'targtype1_txt', 'weaptype1_txt']\n",
    "\n",
    "# Define targets\n",
    "target_regression = 'nkill'  # Predicting fatalities\n",
    "target_classification = 'attacktype1_txt'  # Predicting attack type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for Regression Task\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(df[features_reg], df[target_regression], test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting data for Classification Task\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(df[features_clf], df[target_classification], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_reg = scaler.fit_transform(X_train_reg)\n",
    "X_test_reg = scaler.transform(X_test_reg)\n",
    "X_train_clf = scaler.fit_transform(X_train_clf)\n",
    "X_test_clf = scaler.transform(X_test_clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost Regressor\n",
    "regressor = xgb.XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_reg = regressor.predict(X_test_reg)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nðŸ”¹ Regression Model Performance (Predicting Fatalities):\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test_reg, y_pred_reg):.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test_reg, y_pred_reg):.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test_reg, y_pred_reg)):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_clf = classifier.predict(X_test_clf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nðŸ”¹ Classification Model Performance (Predicting Attack Type):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_clf, y_pred_clf):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_clf, y_pred_clf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Display best parameters\n",
    "print(\"\\nðŸ”¹ Best Parameters for Classification Model:\", grid_search.best_params_)\n",
    "print(f\"Best Accuracy: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow if not installed\n",
    "!pip install tensorflow\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Regression Neural Network\n",
    "regressor_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_reg.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "regressor_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history_reg = regressor_model.fit(X_train_reg, y_train_reg, epochs=50, batch_size=32, validation_data=(X_test_reg, y_test_reg), verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_reg = regressor_model.predict(X_test_reg)\n",
    "print(\"\\nðŸ”¹ Regression Model Performance:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test_reg, y_pred_reg):.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test_reg, y_pred_reg):.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test_reg, y_pred_reg)):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical format for multi-class classification\n",
    "num_classes = len(np.unique(y_train_clf))\n",
    "y_train_clf_categorical = keras.utils.to_categorical(y_train_clf, num_classes)\n",
    "y_test_clf_categorical = keras.utils.to_categorical(y_test_clf, num_classes)\n",
    "\n",
    "# Build the Classification Neural Network\n",
    "classifier_model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_clf.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # Softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_clf = classifier_model.fit(X_train_clf, y_train_clf_categorical, epochs=50, batch_size=32, validation_data=(X_test_clf, y_test_clf_categorical), verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_clf_prob = classifier_model.predict(X_test_clf)\n",
    "y_pred_clf = np.argmax(y_pred_clf_prob, axis=1)\n",
    "\n",
    "print(\"\\nðŸ”¹ Classification Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_clf, y_pred_clf):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_clf, y_pred_clf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ”¹ Classification Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_clf, y_pred_clf):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_clf, y_pred_clf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
